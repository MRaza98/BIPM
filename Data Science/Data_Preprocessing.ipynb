{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Train/Test Split"]},{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-06-21T08:27:49.022629Z","iopub.status.busy":"2022-06-21T08:27:49.02211Z","iopub.status.idle":"2022-06-21T08:27:49.043911Z","shell.execute_reply":"2022-06-21T08:27:49.04287Z","shell.execute_reply.started":"2022-06-21T08:27:49.02259Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684323128705,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"JMOUMMcxCoOH","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# predict Species\n","iris_df = pd.read_csv('/Users/muhammadraza/Documents/GitHub/BIPM/Data Science/data/Dataset_Iris.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 150 entries, 0 to 149\n","Data columns (total 6 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   Id                 150 non-null    int64  \n"," 1   Sepal Length (cm)  150 non-null    float64\n"," 2   Sepal Width (cm)   150 non-null    float64\n"," 3   Petal Length (cm)  150 non-null    float64\n"," 4   Petal Width (cm)   150 non-null    float64\n"," 5   Species            150 non-null    object \n","dtypes: float64(4), int64(1), object(1)\n","memory usage: 7.2+ KB\n"]}],"source":["iris_df.info()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Step 1: separate training data from prediction target\n","# =====================================================\n","# (also get rid of Id-column)\n","# Naming convention: training data = X; prediction target = y\n","X = iris_df.drop(columns = [\"Species\"])\n","y = iris_df[\"Species\"]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Step 2: Apply Train/Test Split\n","# ==============================\n","# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","# function will shuffle the dataset before separation (good)\n","# test-size: 20-30% of the data (rule of thumb)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Sepal Length (cm)</th>\n","      <th>Sepal Width (cm)</th>\n","      <th>Petal Length (cm)</th>\n","      <th>Petal Width (cm)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>98</th>\n","      <td>99</td>\n","      <td>5.1</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>1.1</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>69</td>\n","      <td>6.2</td>\n","      <td>2.2</td>\n","      <td>4.5</td>\n","      <td>1.5</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>5.1</td>\n","      <td>3.8</td>\n","      <td>1.5</td>\n","      <td>0.3</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>144</td>\n","      <td>6.8</td>\n","      <td>3.2</td>\n","      <td>5.9</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>100</td>\n","      <td>5.7</td>\n","      <td>2.8</td>\n","      <td>4.1</td>\n","      <td>1.3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>38</td>\n","      <td>4.9</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.1</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>80</td>\n","      <td>5.7</td>\n","      <td>2.6</td>\n","      <td>3.5</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>34</td>\n","      <td>5.5</td>\n","      <td>4.2</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>95</td>\n","      <td>5.6</td>\n","      <td>2.7</td>\n","      <td>4.2</td>\n","      <td>1.3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>105 rows × 5 columns</p>\n","</div>"],"text/plain":["      Id  Sepal Length (cm)  Sepal Width (cm)  Petal Length (cm)  \\\n","98    99                5.1               2.5                3.0   \n","68    69                6.2               2.2                4.5   \n","19    20                5.1               3.8                1.5   \n","143  144                6.8               3.2                5.9   \n","99   100                5.7               2.8                4.1   \n","..   ...                ...               ...                ...   \n","37    38                4.9               3.1                1.5   \n","79    80                5.7               2.6                3.5   \n","33    34                5.5               4.2                1.4   \n","94    95                5.6               2.7                4.2   \n","3      4                4.6               3.1                1.5   \n","\n","     Petal Width (cm)  \n","98                1.1  \n","68                1.5  \n","19                0.3  \n","143               2.3  \n","99                1.3  \n","..                ...  \n","37                0.1  \n","79                1.0  \n","33                0.2  \n","94                1.3  \n","3                 0.2  \n","\n","[105 rows x 5 columns]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["X_train"]},{"cell_type":"markdown","metadata":{"id":"5g2powimCoOM"},"source":["# 1. Quick Sanity Checks for your Dataset\n","\n","Possible Problems\n","- Duplicated rows\n","- Numbers are saved as strings\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0dQmjPQFbg_Y"},"source":["## 1.1 Check for duplicated values"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":583},"execution":{"iopub.execute_input":"2022-06-21T08:28:51.61072Z","iopub.status.busy":"2022-06-21T08:28:51.610158Z","iopub.status.idle":"2022-06-21T08:28:51.74549Z","shell.execute_reply":"2022-06-21T08:28:51.744718Z","shell.execute_reply.started":"2022-06-21T08:28:51.610656Z"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1684323130710,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"rJwnHaUoCoOJ","outputId":"8b53abec-5182-45ae-b4ee-6f34b2714dae","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>type</th>\n","      <th>description</th>\n","      <th>release_year</th>\n","      <th>age_certification</th>\n","      <th>runtime</th>\n","      <th>genres</th>\n","      <th>production_countries</th>\n","      <th>seasons</th>\n","      <th>imdb_id</th>\n","      <th>imdb_score</th>\n","      <th>imdb_votes</th>\n","      <th>tmdb_popularity</th>\n","      <th>tmdb_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ts300399</td>\n","      <td>Five Came Back: The Reference Films</td>\n","      <td>SHOW</td>\n","      <td>This collection includes 12 World War II-era p...</td>\n","      <td>1945</td>\n","      <td>TV-MA</td>\n","      <td>48</td>\n","      <td>['documentation']</td>\n","      <td>['US']</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.600</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>tm84618</td>\n","      <td>Taxi Driver</td>\n","      <td>MOVIE</td>\n","      <td>A mentally unstable Vietnam War veteran works ...</td>\n","      <td>1976</td>\n","      <td>R</td>\n","      <td>113</td>\n","      <td>['crime', 'drama']</td>\n","      <td>['US']</td>\n","      <td>NaN</td>\n","      <td>tt0075314</td>\n","      <td>8.3</td>\n","      <td>795222.0</td>\n","      <td>27.612</td>\n","      <td>8.2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>tm127384</td>\n","      <td>Monty Python and the Holy Grail</td>\n","      <td>MOVIE</td>\n","      <td>King Arthur, accompanied by his squire, recrui...</td>\n","      <td>1975</td>\n","      <td>PG</td>\n","      <td>91</td>\n","      <td>['comedy', 'fantasy']</td>\n","      <td>['GB']</td>\n","      <td>NaN</td>\n","      <td>tt0071853</td>\n","      <td>8.2</td>\n","      <td>530877.0</td>\n","      <td>18.216</td>\n","      <td>7.8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>tm70993</td>\n","      <td>Life of Brian</td>\n","      <td>MOVIE</td>\n","      <td>Brian Cohen is an average young Jewish man, bu...</td>\n","      <td>1979</td>\n","      <td>R</td>\n","      <td>94</td>\n","      <td>['comedy']</td>\n","      <td>['GB']</td>\n","      <td>NaN</td>\n","      <td>tt0079470</td>\n","      <td>8.0</td>\n","      <td>392419.0</td>\n","      <td>17.505</td>\n","      <td>7.8</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>tm190788</td>\n","      <td>The Exorcist</td>\n","      <td>MOVIE</td>\n","      <td>12-year-old Regan MacNeil begins to adapt an e...</td>\n","      <td>1973</td>\n","      <td>R</td>\n","      <td>133</td>\n","      <td>['horror']</td>\n","      <td>['US']</td>\n","      <td>NaN</td>\n","      <td>tt0070047</td>\n","      <td>8.1</td>\n","      <td>391942.0</td>\n","      <td>95.337</td>\n","      <td>7.7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                title   type  \\\n","0  ts300399  Five Came Back: The Reference Films   SHOW   \n","1   tm84618                          Taxi Driver  MOVIE   \n","2  tm127384      Monty Python and the Holy Grail  MOVIE   \n","3   tm70993                        Life of Brian  MOVIE   \n","4  tm190788                         The Exorcist  MOVIE   \n","\n","                                         description  release_year  \\\n","0  This collection includes 12 World War II-era p...          1945   \n","1  A mentally unstable Vietnam War veteran works ...          1976   \n","2  King Arthur, accompanied by his squire, recrui...          1975   \n","3  Brian Cohen is an average young Jewish man, bu...          1979   \n","4  12-year-old Regan MacNeil begins to adapt an e...          1973   \n","\n","  age_certification  runtime                 genres production_countries  \\\n","0             TV-MA       48      ['documentation']               ['US']   \n","1                 R      113     ['crime', 'drama']               ['US']   \n","2                PG       91  ['comedy', 'fantasy']               ['GB']   \n","3                 R       94             ['comedy']               ['GB']   \n","4                 R      133             ['horror']               ['US']   \n","\n","   seasons    imdb_id  imdb_score  imdb_votes  tmdb_popularity  tmdb_score  \n","0      1.0        NaN         NaN         NaN            0.600         NaN  \n","1      NaN  tt0075314         8.3    795222.0           27.612         8.2  \n","2      NaN  tt0071853         8.2    530877.0           18.216         7.8  \n","3      NaN  tt0079470         8.0    392419.0           17.505         7.8  \n","4      NaN  tt0070047         8.1    391942.0           95.337         7.7  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Netflix-dataset\n","netflix_df = pd.read_csv(\"/Users/muhammadraza/Documents/GitHub/BIPM/Data Science/data/Dataset_Netflix.csv\")\n","netflix_df.head()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1276,"status":"ok","timestamp":1684323173194,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"dHqm-PGSbgRx","outputId":"0670d5d1-a77b-4e3f-fc64-acb86a5db7a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]}],"source":["print(netflix_df.duplicated().sum())"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"rMgHpiWCb02P"},"outputs":[],"source":["# In case of dupliacted rows: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html\n","netflix_df.drop_duplicates(inplace = True)"]},{"cell_type":"markdown","metadata":{"id":"B6oBM5LscRuq"},"source":["## 1.2 Check for wrong datatypes\n","Pandas datatypes (64 refers to the amount of memory that is used to save a value)\n","- int64 (= int in Python)\n","- float64 (= float in Python)\n","- object (= string in Python)\n","- datetime64 (= datetime)\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":449,"status":"ok","timestamp":1684323505687,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"pXZrhC3UcjWJ","outputId":"8174ae9a-1be6-4190-bff8-e6aab146e501"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5806 entries, 0 to 5805\n","Data columns (total 15 columns):\n"," #   Column                Non-Null Count  Dtype  \n","---  ------                --------------  -----  \n"," 0   id                    5806 non-null   object \n"," 1   title                 5805 non-null   object \n"," 2   type                  5806 non-null   object \n"," 3   description           5788 non-null   object \n"," 4   release_year          5806 non-null   int64  \n"," 5   age_certification     3196 non-null   object \n"," 6   runtime               5806 non-null   int64  \n"," 7   genres                5806 non-null   object \n"," 8   production_countries  5806 non-null   object \n"," 9   seasons               2047 non-null   float64\n"," 10  imdb_id               5362 non-null   object \n"," 11  imdb_score            5283 non-null   float64\n"," 12  imdb_votes            5267 non-null   float64\n"," 13  tmdb_popularity       5712 non-null   float64\n"," 14  tmdb_score            5488 non-null   float64\n","dtypes: float64(5), int64(2), object(8)\n","memory usage: 680.5+ KB\n"]}],"source":["netflix_df.info()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-06-21T08:42:16.189987Z","iopub.status.busy":"2022-06-21T08:42:16.188677Z","iopub.status.idle":"2022-06-21T08:42:16.236447Z","shell.execute_reply":"2022-06-21T08:42:16.235297Z","shell.execute_reply.started":"2022-06-21T08:42:16.189932Z"},"executionInfo":{"elapsed":223,"status":"ok","timestamp":1684323610426,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"x3fyuxmWCoOM","outputId":"d89fb776-fbe6-4fd2-9018-1e04f561f5a4","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5806 entries, 0 to 5805\n","Data columns (total 15 columns):\n"," #   Column                Non-Null Count  Dtype  \n","---  ------                --------------  -----  \n"," 0   id                    5806 non-null   object \n"," 1   title                 5805 non-null   object \n"," 2   type                  5806 non-null   object \n"," 3   description           5788 non-null   object \n"," 4   release_year          5806 non-null   int64  \n"," 5   age_certification     3196 non-null   object \n"," 6   runtime               5806 non-null   object \n"," 7   genres                5806 non-null   object \n"," 8   production_countries  5806 non-null   object \n"," 9   seasons               2047 non-null   float64\n"," 10  imdb_id               5362 non-null   object \n"," 11  imdb_score            5283 non-null   float64\n"," 12  imdb_votes            5267 non-null   float64\n"," 13  tmdb_popularity       5712 non-null   float64\n"," 14  tmdb_score            5488 non-null   float64\n","dtypes: float64(5), int64(1), object(9)\n","memory usage: 680.5+ KB\n","None\n"]}],"source":["# As an example: convert the runtime column to type string\n","netflix_df[\"runtime\"] = netflix_df[\"runtime\"].astype(\"object\")\n","\n","# Look at the dtypes of the dataset\n","print(netflix_df.info())"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":228,"status":"ok","timestamp":1684323628893,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"1LW6bW04c6zC"},"outputs":[],"source":["# As int is actually ok, we change it back\n","netflix_df[\"runtime\"] = netflix_df[\"runtime\"].astype(int)\n","\n","# Look at the dtypes of the dataset\n","print(netflix_df.info())"]},{"cell_type":"markdown","metadata":{"id":"_LgkbhFICoOJ"},"source":["# 2. Remove and replace missing values (columns/rows)"]},{"cell_type":"markdown","metadata":{"id":"Lnxo8vKLQxj4"},"source":["## 2.1 Remove Missing Values entirely (to be avoided)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-06-21T08:33:20.953533Z","iopub.status.busy":"2022-06-21T08:33:20.953091Z","iopub.status.idle":"2022-06-21T08:33:20.97936Z","shell.execute_reply":"2022-06-21T08:33:20.978663Z","shell.execute_reply.started":"2022-06-21T08:33:20.953501Z"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1684323995116,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"HdPWO1BOCoOK","outputId":"5ad77aa7-4c6c-495a-d56b-a9ecf5886ba1","trusted":true},"outputs":[],"source":["# Example 1: Remove rows with null values from individual columns\n","\n","# Count missing values in each column\n","print(\"Initial length:\", len(netflix_df), \"rows\")\n","print(netflix_df.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1684324055728,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"kSc2KoqKPTfk","outputId":"d5a9c44f-2261-4e59-b87e-e558121c98d2"},"outputs":[],"source":["# Create a new df where we remove missing values from the \"description\"-column\n","netflix_df_subset = netflix_df[netflix_df[\"description\"].notnull()]\n","    \n","print(\"New length:\", len(netflix_df_subset), \"rows\")\n","print(netflix_df_subset.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-06-21T08:36:58.407029Z","iopub.status.busy":"2022-06-21T08:36:58.4066Z","iopub.status.idle":"2022-06-21T08:36:58.444298Z","shell.execute_reply":"2022-06-21T08:36:58.443242Z","shell.execute_reply.started":"2022-06-21T08:36:58.406997Z"},"executionInfo":{"elapsed":1210,"status":"ok","timestamp":1684324346010,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"eQrrQD1jCoOK","outputId":"c5fcc21d-7144-4e42-bb01-5cd001cf9820","trusted":true},"outputs":[],"source":["# Example 2: Drop entire columns or rows\n","#  - source: # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n","\n","# remove all rows that contain empty values\n","without_rows_df = netflix_df_subset.dropna(axis=0)\n","print(\"Removed rows with missing values.\")\n","print(\"New length:\", len(without_rows_df), \"rows\")\n","print(without_rows_df.isnull().sum())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1684324376298,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"NKp6VuY-QZk_","outputId":"4c1bd0c4-9de3-4810-e1d1-ab578406e771"},"outputs":[],"source":["# remove all columns that contain empty values\n","without_columns_df = netflix_df_subset.dropna(axis=1)\n","print(\"Removed columns with missing values:\")\n","print(without_columns_df.isnull().sum())"]},{"cell_type":"markdown","metadata":{"id":"-8OuSVKGQ8qh"},"source":["## 2.2 Replace missing values (better strategy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1684324434573,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"66YNQogjRDtt","outputId":"a51f4773-ed77-4a70-aa79-43e388e29e63"},"outputs":[],"source":["# Reload Netflix-dataset\n","netflix_df = pd.read_csv(\"../data/Dataset_Netflix.csv\")\n","netflix_df.info()"]},{"cell_type":"markdown","metadata":{"id":"94C2NuE0T4dF"},"source":["### 2.2.1 Strategy: Replace missing values with the mean\n","For numeric values without outliers: replace missing values with the mean"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":583},"executionInfo":{"elapsed":1206,"status":"ok","timestamp":1684324463280,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"mgkF10JYTVG2","outputId":"2f63c9e2-5ee0-4d1d-f173-0c968e723fb7"},"outputs":[],"source":["netflix_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Changes output of the transformers to Pandas\n","from sklearn import set_config\n","set_config(transform_output=\"pandas\")\n","\n","# import the imputing function\n","from sklearn.impute import SimpleImputer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# define imputer and strategy\n","imputer = SimpleImputer(strategy=\"mean\", add_indicator=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# applying fit and transform separately\n","imputer.fit(netflix_df[['imdb_votes']])\n","\n","# need to assign the output of the imputer to 2 columns\n","# the original columns gets overwritten and a new column contains the indicator\n","netflix_df[['imdb_votes', 'missingindicator_imdb_votes']] = imputer.transform(netflix_df[['imdb_votes']])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["netflix_df[['imdb_votes', 'missingindicator_imdb_votes']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# applying fit and transform together\n","\n","# Reload Netflix-dataset\n","netflix_df = pd.read_csv(\"../data/Dataset_Netflix.csv\")\n","\n","# apply fit and transform\n","netflix_df[['imdb_votes', 'missingindicator_imdb_votes']] = imputer.fit_transform(netflix_df[['imdb_votes']])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["netflix_df[['imdb_votes', 'missingindicator_imdb_votes']]"]},{"cell_type":"markdown","metadata":{"id":"XXskFR1QUvQh"},"source":["### 2.2.2 Strategy: Replace missing values with the median\n","For numeric values with outliers: replace missing values with the median"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(netflix_df.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":420,"status":"ok","timestamp":1684324706826,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"8D8lOvjlU3mT","outputId":"db3493f7-fef1-467a-a46a-b62c59b5e7b1"},"outputs":[],"source":["# Check for outliers\n","netflix_df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":423,"status":"ok","timestamp":1684324831939,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"8zG5otx1U3vA"},"outputs":[],"source":["# Column \"tmdb_popularity\" has a high max compared to the mean - most likely outliers\n","# Let's investigate a bit deeper...\n","netflix_check = netflix_df.sort_values(by = \"tmdb_popularity\", ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1684324841713,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"u2rsdGAqU3ze","outputId":"88ea5cf2-3170-4961-baf4-50b9e8403379"},"outputs":[],"source":["# tmdb_popularity seems to have outliers\n","netflix_check.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# define imputer and strategy\n","imputer = SimpleImputer(strategy=\"median\", add_indicator=True)\n","\n","# applying fit and transform together\n","netflix_df[['tmdb_popularity', 'missingindicator_tmdb_popularity']] = imputer.fit_transform(netflix_df[['tmdb_popularity']])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1684324936765,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"gI5LWxWIWY0W","outputId":"f3b42e9d-106e-41f8-dd1d-fa08f9c44f9c"},"outputs":[],"source":["# check for null-values\n","print(netflix_df.isnull().sum())"]},{"cell_type":"markdown","metadata":{"id":"X3oeQt--UsWf"},"source":["### 2.2.3 Strategy: Replace missing values with the mode\n","For categorical values: replace missing values with the mode"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":248,"status":"ok","timestamp":1684325190156,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"KhbrgTkfiDlw","outputId":"65358c32-d631-4e01-a8c6-5fcf7a1e3934"},"outputs":[],"source":["netflix_df['age_certification'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247,"status":"ok","timestamp":1684325277149,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"cAKBgCxCXl4-","outputId":"9183ae62-d1df-4cf9-bb05-94edef146fd4"},"outputs":[],"source":["# define imputer and strategy\n","imputer = SimpleImputer(strategy=\"most_frequent\", add_indicator=True)\n","\n","# applying fit and transform together\n","netflix_df[['age_certification', 'missingindicator_age_certification']] = imputer.fit_transform(netflix_df[['age_certification']])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1684325293458,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"RQrCCZCNh8g5","outputId":"8e4a17c6-ecd3-4198-ff39-2bee9a39ead0"},"outputs":[],"source":["netflix_df['age_certification'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2.4 Column Transformer: Applying transformations to multiple columns "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# reload dataset\n","netflix_df = pd.read_csv('../data/Dataset_Netflix.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","\n","imputer_mean = SimpleImputer(strategy=\"mean\", add_indicator=True)\n","\n","ct = ColumnTransformer(\n","    [('imputer', imputer_mean, ['imdb_votes'])],\n","    remainder='passthrough'\n",")\n","\n","ct.fit_transform(netflix_df)"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2.5 Exercise"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# a) Define train-test split for Netflix Dataset\n","#       - prediction-target = imdb_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# b) Define transformations for selected columns with SimpleImputer and column transformer\n","#       - imdb_votes --> mean\n","#       - tmdb_popularity --> median/most frequent\n","#       - age_certification --> mode\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# c) apply transformations to X_train and X_test\n"]},{"cell_type":"markdown","metadata":{"id":"Kbcm9hIBCoOM"},"source":["<a class=\"anchor\" id=\"chapter_3\"></a>\n","\n","# 3. Stratify Sample Populations\n","\n","- When to use: If class values are imbalanced (but actually, it can could be used all the time...)\n","- train_test_split() contains a parameter that keeps the original distribution of values for train/test splits"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1639,"status":"ok","timestamp":1684325792655,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"lqAZYLT8kiX3","outputId":"1c52b13c-5f02-453b-fb23-9a73db2940d1"},"outputs":[],"source":["# Load IRIS-dataset\n","iris_df = pd.read_csv('../data/Dataset_Iris.csv')\n","iris_df.head()"]},{"cell_type":"markdown","metadata":{"id":"0KdBoTbsl_aq"},"source":["## 3.1 Train-Test split without stratification"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1168,"status":"ok","timestamp":1684326200177,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"qct7r-EPksqb"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Create training set\n","# as we want to predict the species, we need to create X as a dataframe without this column\n","X = iris_df.drop(\"Species\", axis=1)\n","\n","# We save the species-column in a separate dataframe\n","y = iris_df[[\"Species\"]]\n","\n","# Perform Train and test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5 ,stratify=None, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1684326202621,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"9ZCDVSLHks3R","outputId":"a410318b-2760-411f-d956-7f23ad7a1d9a"},"outputs":[],"source":["print(\"Original Distribution:\")\n","print(y[\"Species\"].value_counts())\n","print()\n","print(\"Distribution of values in train set without stratification:\")\n","print(y_train[\"Species\"].value_counts())"]},{"cell_type":"markdown","metadata":{"id":"UeSqvbYnnM96"},"source":["## 3.2 Train-Test split with stratification\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":210,"status":"ok","timestamp":1684326278798,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"klHRukl3ktEe"},"outputs":[],"source":["# We use stratified sampling to split the data into train split while keeping the species-distribution in train and test-set, respectively\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":221,"status":"ok","timestamp":1684326281625,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"KVHLKgcOmoSi","outputId":"1c626095-1e5c-4c07-becb-c483b406eb30"},"outputs":[],"source":["print(\"Original Distribution:\")\n","print(y[\"Species\"].value_counts())\n","print()\n","print(\"Distribution of values in train set with stratification:\")\n","print(y_train[\"Species\"].value_counts())"]},{"cell_type":"markdown","metadata":{"id":"DlXiHAIGCoON"},"source":["<a class=\"anchor\" id=\"chapter_4\"></a>\n","\n","# 4. Standardization for Numerical Variables\n","\n","- Problem: High variance in different classes in a dataset\n","- **These methods are applied to continuous numerical data (not to classes/categories)**\n","- When to use?\n","  - Especially important for KNN, because the values in KNN are calculated by using a linear distance metric\n","  - if features have a high variance\n","  - if features are continuous and on a different scale (e.g. age, weight)\n","  - can improve performance of other models as well (e.g., decision trees)\n","\n","Standardization\n","- Values are centered around the mean and scaled to z-values (measured in standard distributions)\n","- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n","- https://www.statisticshowto.com/probability-and-statistics/z-score/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example dataframe\n","X_train = pd.DataFrame({'age':[10, 100, 19, 21, 25], \n","                        'income':[10000, 20000, 100000, 50000, 30000]})\n","\n","X_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train.std()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit_transform(X_train)"]},{"cell_type":"markdown","metadata":{},"source":["## 4.1 Application on Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exercise with wine_df\n","wine_df = pd.read_csv(\"../data/Dataset_Red_Wine_Quality.csv\")\n","\n","X = wine_df.drop(columns=\"quality\")\n","y = wine_df[\"quality\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n","\n","# Potential problem: high variance in a dataset:\n","print(X_train.var())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3141,"status":"ok","timestamp":1684329149139,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"ZLpMBX2htmGP","outputId":"b0dfaf4c-8a9e-44dc-a0f8-7eb80086441e"},"outputs":[],"source":["# Another problem: different value ranges (see x-axes)\n","import matplotlib.pyplot as plt\n","X_train.hist(figsize=(14, 10))\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use standard Scaler with column-transformer\n","ss = StandardScaler()\n","\n","columns_to_transform = X_train.columns\n","\n","ct_standardization = ColumnTransformer(\n","    [('standard_scaler', ss, X_train.columns)],\n","    remainder='passthrough'\n",")\n","\n","X_train = ct_standardization.fit_transform(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train.var()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# show distributions \n","import matplotlib.pyplot as plt\n","X_train.hist(figsize=(14, 10))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"executionInfo":{"elapsed":246,"status":"ok","timestamp":1684329543384,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"HEQIja9Oz36L"},"source":["## 4.2 Application of different Scalers\n","\n","- Problem: we still have skewed distributions in some of the variables.\n","- For those, standardization did not have the desired effect\n","- Let's create two lists: columns that work well with StandardScaler and columns that doesn not.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use PowerTransformer for columns where StandardScaler did not work properly\n","from sklearn.preprocessing import PowerTransformer\n","\n","wine_df = pd.read_csv(\"../data/Dataset_Red_Wine_Quality.csv\")\n","\n","X = wine_df.drop(columns=\"quality\")\n","y = wine_df[\"quality\"]\n","\n","# train test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n","\n","ss = StandardScaler()\n","pt = PowerTransformer()\n","\n","# columns that show a normal distribution (or very similar) after StandardScaler was applied\n","columns_StandardScaler = [\"density\", \"pH\", 'sulphates', 'alcohol', 'fixed acidity', 'volatile acidity', 'chlorides', 'citric acid']\n","\n","# for the most obvious skewed distributions, we create another list \n","columns_skewed_distribution = ['free sulfur dioxide', 'total sulfur dioxide', 'residual sugar']\n","\n","ct_standardization = ColumnTransformer(\n","    [('standard_scaler', ss, columns_StandardScaler),\n","    ('power_transfomer', pt, columns_skewed_distribution)],\n","    remainder='passthrough'\n",")\n","\n","X_train = ct_standardization.fit_transform(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train.var()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# show distributions \n","import matplotlib.pyplot as plt\n","X_train.hist(figsize=(14, 10))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ynzlyCktCoOQ"},"source":["# 5. Dummy Coding\n","\n","Encoding of categorical variables"]},{"cell_type":"markdown","metadata":{},"source":["## 5.1 One-Hot encoding of categorical variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train = pd.DataFrame({'shape':['square', 'square', 'oval', 'circle']})\n","X_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# left to right the columns are in alphabetical sequence (circle, oval, square)\n","ohe = OneHotEncoder(sparse_output=False)\n","ohe.fit_transform(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ohe.get_feature_names_out()"]},{"cell_type":"markdown","metadata":{},"source":["## 5.2 Ordinal encoding for categorical features"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train = pd.DataFrame({'rating':['very good', 'very bad', 'very good', 'OK', 'good', 'very good','bad']})\n","X_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import OrdinalEncoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the order of categories\n","categories = [['very bad', 'bad', 'OK', 'good', 'very good']]\n","oe = OrdinalEncoder(categories=categories)\n","oe.fit_transform(X_train)"]},{"cell_type":"markdown","metadata":{},"source":["## 5.3 Application to dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"execution":{"iopub.execute_input":"2022-06-21T09:11:06.508524Z","iopub.status.busy":"2022-06-21T09:11:06.508062Z","iopub.status.idle":"2022-06-21T09:11:06.535457Z","shell.execute_reply":"2022-06-21T09:11:06.534321Z","shell.execute_reply.started":"2022-06-21T09:11:06.50849Z"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1684331068971,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"JD9rKOhCCoOQ","outputId":"0203077a-1e4f-4fc7-f331-437183e74ea0","trusted":true},"outputs":[],"source":["iris_df = pd.read_csv(\"../data/Dataset_Iris.csv\")\n","iris_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder\n","\n","ohe = OneHotEncoder(sparse_output=False)\n","\n","ct_one_hot = ColumnTransformer(\n","    [('OneHotEncoder', ohe, [\"Species\"])],\n","    remainder='passthrough'\n",")\n","\n","ct_one_hot.fit_transform(iris_df)\n"]},{"cell_type":"markdown","metadata":{"id":"FeBK-v-yCoOR"},"source":["<a class=\"anchor\" id=\"chapter_6\"></a>\n","\n","# 6. Feature Selection\n","Source: https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/\n","\n","Goal: remove unnecessary features from dataset that might create noise\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QijCFoW0nOKc"},"source":["## 6.1 Correlation Matrix\n","\n","*   Good features correlate highly with the prediction target\n","*   Good features do not correlate among themselves"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":268},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1684331415709,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"sxnBJ-sYnpI5","outputId":"5d875f2a-3069-4b51-8c5b-56edf342836a"},"outputs":[],"source":["# Prediction of quality-levels based wine-features\n","wine_df = pd.read_csv(\"../data/Dataset_Red_Wine_Quality.csv\")\n","wine_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":662},"executionInfo":{"elapsed":2729,"status":"ok","timestamp":1684331449787,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"dz4guqetj2bI","outputId":"0d80fb69-6ab1-46d2-deda-a53895ef4bd6"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# correlation matrix\n","cor = wine_df.corr()\n","\n","plt.figure(figsize=(10,6))\n","sns.heatmap(cor, annot=True)\n"]},{"cell_type":"markdown","metadata":{"id":"XUJ_BOQEjEIz"},"source":["## 6.2 Information Gain\n","* Information gain calculates the reduction in entropy\n","* It can be used for feature selection by evaluating the Information gain of each variable in the context of the target variable.\n","*   High values indicate a strong predictive power\n","* https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":546},"executionInfo":{"elapsed":1698,"status":"ok","timestamp":1684331719586,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"NMCF0oOAh4de","outputId":"dde78f31-ea8f-4d69-9ddd-a11e08ea4618"},"outputs":[],"source":["from sklearn.feature_selection import mutual_info_classif\n","import matplotlib.pyplot as plt\n","\n","X = wine_df.drop(\"quality\", axis=1)\n","y = wine_df[\"quality\"]\n","\n","importances = mutual_info_classif(X, y)\n","feature_importances = pd.Series(importances, wine_df.columns[0:len(wine_df.columns)-1])\n","feature_importances.plot(kind=\"bar\", color=\"teal\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"EjpYZ6NOpWZ3"},"source":["## 6.3 Automated Methods\n","Link: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":293,"status":"ok","timestamp":1684332017266,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"70z2BinRjbpa"},"outputs":[],"source":["from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2, f_regression\n","from numpy import array \n","\n","iris_df = pd.read_csv(\"../data/Dataset_Iris.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219,"status":"ok","timestamp":1684332077753,"user":{"displayName":"Sebastian Hüttemann","userId":"10203859981941493139"},"user_tz":-120},"id":"uIRiepYUpbR-","outputId":"04b948ff-9225-427a-d4a7-fde2df92a4d8"},"outputs":[],"source":["# Create training set and prediction target\n","X = iris_df.drop(\"Species\", axis=1)\n","y = iris_df[[\"Species\"]]\n","\n","# Perform feature selection\n","# Set k to the number of features you want to identify\n","select = SelectKBest(score_func=chi2, k=3)\n","select.fit_transform(X,y)\n","\n","# Print feature names\n","filter = select.get_support() \n","features = array(X.columns)\n","\n","print(\"All features:\")\n","print(features)\n"," \n","print(\"Selected best 3:\")\n","print(features[filter])\n"]},{"cell_type":"markdown","metadata":{"id":"j2ly9yzFp1Ny"},"source":["# 7. Pipelines"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.pipeline import Pipeline\n","\n","# define classifier (= ML-model)\n","clf = DecisionTreeClassifier()\n","\n","# Define dataset\n","wine_df = pd.read_csv(\"../data/Dataset_Red_Wine_Quality.csv\")\n","X = wine_df.drop(columns=\"quality\")\n","y = wine_df[\"quality\"]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n","\n","# Add Preprocessing Steps\n","ss = StandardScaler()\n","pt = PowerTransformer()\n","columns_StandardScaler = [\"density\", \"pH\", 'sulphates', 'alcohol', 'fixed acidity', 'volatile acidity', 'chlorides', 'citric acid']\n","columns_skewed_distribution = ['free sulfur dioxide', 'total sulfur dioxide', 'residual sugar']\n","ct = ColumnTransformer(\n","    [('standard_scaler', ss, columns_StandardScaler),\n","    ('power_transfomer', pt, columns_skewed_distribution)],\n","    remainder='passthrough'\n",")\n","\n","# create pipeline\n","pipe = Pipeline([\n","    ('preprocessor', ct),\n","    ('classifier', clf)]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pipe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pipe.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = pipe.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
