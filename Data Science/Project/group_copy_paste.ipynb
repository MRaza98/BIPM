{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group: CopyPaste\n",
    "#### Dataset used: Dataset_Hospital_Vists.csv, test.csv\n",
    "#### Participants: Ligia, Gina, Raza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents Draft\n",
    "\n",
    "1. Problem and Goal Definition\n",
    "2. Data Understanding\n",
    "\n",
    "        2.1 Dataset Description\n",
    "        2.2 Quick Analysis from Kaggle\n",
    "3. Data Quality Check\n",
    "4. Exploratory Data Analysis\n",
    "\n",
    "        4.1 Target Variable Distribution \n",
    "        4.2 Relationships between variables\n",
    "5. Data Cleaning and Preprocessing\n",
    "\n",
    "        5.1 Updating Existing Features\n",
    "        5.2 Adding new features\n",
    "6. Train-Test Split\n",
    "7. Model Selection\n",
    "8. Model Training\n",
    "9. Model Evaluation\n",
    "10. Model Interpretation\n",
    "11. Fine-Tuning and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem and Goal Definition\n",
    "Problem: Patients in a hospital miss their scheduled appointments.\n",
    "\n",
    "Goal: Develop a machine learning model that predicts if a patient will miss a future appointment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Understanding\n",
    "#### 2.1 Dataset Description\n",
    "\n",
    "- The dataset is at appointment level granularity and contains detail of each appointment and patient.\n",
    "\n",
    "- It has 14 columns of which 1 will be our target variable: No-show.\n",
    "\n",
    "- We mostly have information about an appointment's date and place and the patients' health details. A column also shows if a patient received an SMS before the appointment.\n",
    "\n",
    "#### 2.2 Quick Analysis from Kaggle\n",
    "\n",
    "- There is missing data in the columns Age, Community, Social Welfare, and some diseases.\n",
    "- Female to Male ratio is 65:35.\n",
    "- We have no NULLs in the target variable.\n",
    "- For Handcap, we have multiple values even though it seems to be a binary variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Quality Check\n",
    "\n",
    "- Uniqueness\n",
    "- Missing data\n",
    "- Data type consistency check\n",
    "- Distribution of Categorical Variables\n",
    "- Dates inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up environment with packages\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "df = pd.read_csv(\"/Users/muhammadraza/Documents/GitHub/BIPM/Data Science/Project/Dataset_Hospital_Visits.csv\")\n",
    "df.head()\n",
    "\n",
    "# Increase seaborn default resolution\n",
    "sns.set(rc={\"figure.dpi\":150, 'savefig.dpi':150})\n",
    "sns.set_context('notebook')\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set(rc={'figure.figsize':(5,6)})\n",
    "\n",
    "# Give variables to color numbers\n",
    "\n",
    "green = '#008000'\n",
    "red = '#ff0000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uniqueness\n",
    "\n",
    "# Is each row unique?\n",
    "\n",
    "print(\"Duplicate rows: \" + str(df.duplicated().sum()))\n",
    "\n",
    "# Is each appointmentID unique?\n",
    "\n",
    "print(\"Duplicate appointments: \" + str(df['AppointmentID'].duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that the dataset only containts unique IDs and no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Data\n",
    "\n",
    "# Which columns have missing data?\n",
    "\n",
    "missing_data = df.isnull().sum()\n",
    "total_entries = len(df)\n",
    "percentage_missing = round((missing_data / total_entries) * 100, 2)\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage Missing': percentage_missing\n",
    "})\n",
    "\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from Kaggle, Age, Community, SocialWelfare, Hipertension, and Alcoholism have significant null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Type Consistency\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PatientId and Age are to be converted to int from float as IDs must be int/str and ages are usually considered in whole number terms.\n",
    "2. ScheduledDate and AppointmentDate must be timestamps and not objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Categorical Variables\n",
    "\n",
    "occ = df.groupby('Handcap').size().reset_index()\n",
    "print(occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates inconsistency\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "df['AppointmentDate'] = df['AppointmentDate'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').date())\n",
    "df['ScheduledDate'] = df['ScheduledDate'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').date())\n",
    "\n",
    "counts = df['ScheduledDate'] > df['AppointmentDate']\n",
    "occurrence_counts = counts.value_counts()\n",
    "\n",
    "print(occurrence_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 4 incoherent combination of schedule and appointment dates - they will be taken out in data cleaning stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploratory Data Analysis\n",
    "\n",
    "- Distribution of the target variable.\n",
    "- Distribution of age. Which age groups account for the most missing appointments?\n",
    "- Do patients of a certain community miss their appointments more than others?\n",
    "- Do males or females miss more appointments?\n",
    "- How does the time affect the outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribution of the target variable\n",
    "\n",
    "value_counts = df['No-show'].value_counts()\n",
    "\n",
    "labels = value_counts.index\n",
    "sizes = value_counts.values\n",
    "\n",
    "colors = [green,red]  # Customize colors\n",
    "explode = (0.05, 0)  # Explode the 1st slice\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, explode=explode)\n",
    "\n",
    "plt.title('Distribution of No-Show Variable')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures the pie chart is circular\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 in 5 appointments are missed on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which age group misses more appointments?\n",
    "\n",
    "# Plot histogram with split bars\n",
    "\n",
    "plt.hist([df[df['No-show'] == 'No']['Age'], df[df['No-show'] == 'Yes']['Age']],\n",
    "         bins=10, color=['green', 'red'], alpha=0.7, edgecolor='black', label=['No', 'Yes'], stacked=True)\n",
    "\n",
    "plt.title('Overall Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "# To add % later:\n",
    "\n",
    "# n, bins, _ = plt.hist([df[df['No-show'] == 'No']['Age'], df[df['No-show'] == 'Yes']['Age']],\n",
    "#          bins=10, color=['green', 'red'], alpha=0.7, edgecolor='black', label=['No', 'Yes'], stacked=True)\n",
    "\n",
    "# for i in range(len(bins) - 1):\n",
    "#     total = n[0][i] + n[1][i]\n",
    "#     plt.text((bins[i] + bins[i + 1]) / 2, total, f'{n[0][i] / total:.0%}', ha='center', va='bottom')\n",
    "#     plt.text((bins[i] + bins[i + 1]) / 2, total, f'{n[1][i] / total:.0%}', ha='center', va='top')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an even distribution of the ratio of appointments missed in the various age groups. This tends to change after age 70 where appointments are missed a lot less.\n",
    "\n",
    "This could be explained by the fact that older people cannot afford to miss appointments due to more serious health issues and due to the fact that they might have more time on their hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which gender misses more appointments?\n",
    "\n",
    "# Group by 'gender' and 'no_show' and count occurrences\n",
    "grouped_data = df.groupby(['Sex', 'No-show']).size().unstack()\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = grouped_data.div(grouped_data.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Plotting a grouped bar chart\n",
    "ax = percentages.plot(kind='bar', stacked=True, color=[green, red])\n",
    "\n",
    "# Annotate bars with percentages\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.annotate(f'{height:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.title('Gender-wise No-show Distribution')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('# Appointments')\n",
    "plt.legend(title='No-show', loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be 1 in 5 appointments missed for both genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do patients of a certain community miss their appointments more than others?\n",
    "\n",
    "# Count the total number of appointments per community\n",
    "total_appointments_per_community = df['Community'].value_counts()\n",
    "\n",
    "# Sort the DataFrame based on the total number of appointments\n",
    "sorted_df = df[df['Community'].isin(total_appointments_per_community.index)].copy()\n",
    "sorted_df['Community'] = pd.Categorical(sorted_df['Community'], categories=total_appointments_per_community.index, ordered=True)\n",
    "sorted_df = sorted_df.sort_values(by=['Community'])\n",
    "\n",
    "# Count the number of appointments per community split by show_up status\n",
    "appointments_per_community_show_up = sorted_df.groupby(['Community', 'No-show']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar chart for total appointments per community\n",
    "total_appointments_per_community.loc[sorted_df['Community'].unique()].plot(kind='bar', ax=ax, color='blue', label='Total Appointments')\n",
    "\n",
    "# Bar chart for appointments per community split by show_up status\n",
    "appointments_per_community_show_up.plot(kind='bar', stacked=True, ax=ax, color=['green', 'red'], label=['Show Up', 'No Show Up'])\n",
    "\n",
    "# Adding labels and legend\n",
    "ax.set_title('Appointments per Community')\n",
    "ax.set_xlabel('Community')\n",
    "ax.set_ylabel('Number of Appointments')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Cleaning and Preprocessing\n",
    "\n",
    "- Dropping erroneous data\n",
    "- Updating Existing Features: Get the columns into the right data types (has some errors but delayed due to non-urgency)\n",
    "- Updating Existing Features: Handling Missing Data: Extrapolation + Imputation (?)\n",
    "- Adding New Features: Time between ScheduledDate and AppointmentDate\n",
    "- Standardization of Continuous variable: yes or no?\n",
    "- OneHotEncoding for Categorical Vairables\n",
    "- Feature Selection based on Correlation Matrix\n",
    "- Feature Selection based on Information Gain\n",
    "- Feature Selection based on Automated Methods i.e. SelectKBest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping original df intact:\n",
    "\n",
    "df_t = df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Type Consistency\n",
    "\n",
    "df_t.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping erroneous data\n",
    "\n",
    "# Dropping inconsistent dates from transformed dataframe\n",
    "\n",
    "df_t = df_t.drop(df[df['ScheduledDate'] > df['AppointmentDate']].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/muhammadraza/Documents/GitHub/BIPM/Data Science/Project/group_copy_paste.ipynb Cell 30\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/muhammadraza/Documents/GitHub/BIPM/Data%20Science/Project/group_copy_paste.ipynb#Y123sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Dropping outliers for Handcap: 2, 3, 4\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/muhammadraza/Documents/GitHub/BIPM/Data%20Science/Project/group_copy_paste.ipynb#Y123sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m condition \u001b[39m=\u001b[39m (df_t[\u001b[39m'\u001b[39m\u001b[39mHandcap\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39myes\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mall() \u001b[39mor\u001b[39;00m (df_t[\u001b[39m'\u001b[39m\u001b[39mHandcap\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mno\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mall()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/muhammadraza/Documents/GitHub/BIPM/Data%20Science/Project/group_copy_paste.ipynb#Y123sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_t \u001b[39m=\u001b[39m df_t[condition]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "# Dropping outliers for Handcap: 2, 3, 4\n",
    "\n",
    "condition = ((df_t['Handcap'] == 'yes').any() or (df_t['Handcap'] == 'no')).any()\n",
    "\n",
    "df_t = df_t[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PatientId and Age are to be converted to int from float as IDs must be int/str and ages are usually considered in whole number terms.\n",
    "\n",
    "# Has an error!!!\n",
    "\n",
    "# df[\"PatientId\"] = pd.to_numeric(df[\"PatientId\"], errors='coerce').astype(int)\n",
    "# df[\"Age\"] = pd.to_numeric(df[\"Age\"], errors='coerce').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrapolating missing data\n",
    "\n",
    "missing_columns = ['Age', 'Community', 'SocialWelfare', 'Hipertension', 'Alcoholism']\n",
    "\n",
    "for column in missing_columns:\n",
    "    df_t[column] = df_t.groupby('PatientId')[column].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df_t.isnull().sum()\n",
    "total_entries = len(df_t)\n",
    "percentage_missing = round((missing_data / total_entries) * 100, 2)\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage Missing': percentage_missing\n",
    "})\n",
    "\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping missing values for time being. In the future we could also use the KNN imputer to fill empty values.\n",
    "\n",
    "df_t.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprx loss of data (do it later)\n",
    "\n",
    "(1- (df_t.count()/ df.count())) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding New Features: Time between ScheduledDate and AppointmentDate\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "df_t['time_bw_schedule_appointment'] = df_t['AppointmentDate'] - df_t['ScheduledDate']\n",
    "\n",
    "## Convert to float (days)\n",
    "\n",
    "df_t['time_bw_schedule_appointment'] = df_t['time_bw_schedule_appointment'] / pd.Timedelta(days=1)\n",
    "df_t['time_bw_schedule_appointment'] = df_t['time_bw_schedule_appointment'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram with split bars ## EDA and can be removed later.\n",
    "\n",
    "plt.hist([df_t[df_t['No-show'] == 'No']['time_bw_schedule_appointment'], df_t[df_t['No-show'] == 'Yes']['time_bw_schedule_appointment']],\n",
    "         bins=10, color=['green', 'red'], alpha=0.7, edgecolor='black', label=['No', 'Yes'], stacked=True)\n",
    "\n",
    "plt.title('Time Diff Distribution')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take relevant columns for correlation matrix\n",
    "\n",
    "df_sub = df_t[['Diabetes', 'Sex', 'Alcoholism', 'Hipertension', 'SMS_received', 'Handcap', 'time_bw_schedule_appointment', 'No-show']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: Correlation Matrix to understand which features have highest correlation with target variable and less correlation amongst each other.\n",
    "\n",
    "df_t_encoded = pd.get_dummies(df_sub, columns=['Diabetes', 'Sex', 'Alcoholism', 'Hipertension', 'SMS_received', 'Handcap', 'No-show'], drop_first=True).astype(int)\n",
    "correlation_matrix = df_t_encoded.corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection based on Info Gain\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = df_t_encoded.drop(\"No-show_Yes\", axis=1)\n",
    "y = df_t_encoded['No-show_Yes']\n",
    "\n",
    "importances = mutual_info_classif(X, y)\n",
    "feature_importances = pd.Series(importances, df_t_encoded.columns[0:len(df_t_encoded.columns)-1])\n",
    "feature_importances.plot(kind=\"bar\", color=\"teal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_regression, f_classif\n",
    "from numpy import array\n",
    "\n",
    "# Create training set and prediction target\n",
    "X = df_t_encoded.drop(\"No-show_Yes\", axis=1)\n",
    "y = df_t_encoded['No-show_Yes']\n",
    "\n",
    "# Perform feature selection\n",
    "# Set k to the number of features you want to identify\n",
    "select = SelectKBest(score_func=f_classif, k=4)\n",
    "select.fit_transform(X,y)\n",
    "\n",
    "# Print feature names\n",
    "filter = select.get_support() \n",
    "features = array(X.columns)\n",
    " \n",
    "print(\"Selected best:\")\n",
    "print(features[filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_t.drop(columns=['No-show', 'PatientId', 'AppointmentID', 'ScheduledDate', 'AppointmentDate', 'Community'])\n",
    "y = df_t['No-show']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding of Categorical Variables\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='if_binary')\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [('OneHotEncoder', ohe, ['Diabetes', 'Sex', 'Alcoholism', 'Hipertension', 'SMS_received', 'Handcap'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "ct.fit_transform(df_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', ct),\n",
    "    ('classifier', clf)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Model Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Model Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Fine-Tuning and Optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
