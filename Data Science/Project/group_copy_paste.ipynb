{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group: CopyPaste\n",
    "#### Dataset used: Dataset_Hospital_Vists.csv, test.csv\n",
    "#### Participants: Ligia, Gina, Raza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents Draft\n",
    "\n",
    "1. Problem and Goal Definition\n",
    "2. Data Understanding\n",
    "3. Data Quality Check\n",
    "4. Exploratory Data Analysis\n",
    "5. Data Cleaning and Preprocessing\n",
    "6. Train-Test Split\n",
    "7. Model Building\n",
    "8. Model Evaluation\n",
    "9. Model Interpretation\n",
    "10. Fine-Tuning and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem and Goal Definition\n",
    "Problem: Patients in a hospital miss their scheduled appointments.\n",
    "\n",
    "Goal: Develop a machine learning model that predicts if a patient will miss a future appointment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Understanding\n",
    "#### 2.1 Dataset Description\n",
    "\n",
    "- The dataset is at appointment level granularity and contains detail of each appointment and patient.\n",
    "\n",
    "- It has 14 columns of which 1 will be our target variable: No-show.\n",
    "\n",
    "- We mostly have information about an appointment's date and place and the patients' health details. A column also shows if a patient received an SMS before the appointment.\n",
    "\n",
    "#### 2.2 Quick Analysis from Kaggle\n",
    "\n",
    "- There is missing data in the columns Age, Community, Social Welfare, and some diseases.\n",
    "- Female to Male ratio is 65:35.\n",
    "- We have no NULLs in the target variable.\n",
    "- For Handcap, we have multiple values even though it seems to be a binary variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Quality Check\n",
    "\n",
    "- Uniqueness\n",
    "- Missing data\n",
    "- Data type consistency check\n",
    "- Distribution of Categorical Variables\n",
    "- Dates inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up environment with packages\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "df = pd.read_csv(\"/Users/muhammadraza/Documents/GitHub/BIPM/Data Science/Project/Dataset_Hospital_Visits.csv\")\n",
    "df.head()\n",
    "\n",
    "# Increase seaborn default resolution\n",
    "sns.set(rc={\"figure.dpi\":150, 'savefig.dpi':150})\n",
    "sns.set_context('notebook')\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set(rc={'figure.figsize':(5,6)})\n",
    "\n",
    "# Give variables to color numbers\n",
    "\n",
    "green = '#008000'\n",
    "red = '#ff0000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uniqueness\n",
    "\n",
    "# Is each row unique?\n",
    "\n",
    "print(\"Duplicate rows: \" + str(df.duplicated().sum()))\n",
    "\n",
    "# Is each appointmentID unique?\n",
    "\n",
    "print(\"Duplicate appointments: \" + str(df['AppointmentID'].duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that the dataset only containts unique IDs and no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Data\n",
    "\n",
    "# Which columns have missing data?\n",
    "\n",
    "missing_data = df.isnull().sum()\n",
    "total_entries = len(df)\n",
    "percentage_missing = round((missing_data / total_entries) * 100, 2)\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage Missing': percentage_missing\n",
    "})\n",
    "\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from Kaggle, Age, Community, SocialWelfare, Hipertension, and Alcoholism have significant null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Type Consistency\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PatientId and Age are to be converted to int from float as IDs must be int/str and ages are usually considered in whole number terms.\n",
    "2. ScheduledDate and AppointmentDate must be timestamps and not objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Categorical Variables\n",
    "\n",
    "occ = df.groupby('Handcap').size().reset_index()\n",
    "print(occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that this column was meant to be a binary column and the numerical values are bad data. They will be removed during data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates inconsistency\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "df['AppointmentDate'] = df['AppointmentDate'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').date())\n",
    "df['ScheduledDate'] = df['ScheduledDate'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').date())\n",
    "\n",
    "counts = df['ScheduledDate'] > df['AppointmentDate']\n",
    "occurrence_counts = counts.value_counts()\n",
    "\n",
    "print(occurrence_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 4 incoherent combination of schedule and appointment dates - they will be taken out in data cleaning stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploratory Data Analysis\n",
    "\n",
    "- Distribution of the target variable.\n",
    "- Distribution of age. Which age groups account for the most missing appointments?\n",
    "- Do patients of a certain community miss their appointments more than others?\n",
    "- Do males or females miss more appointments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribution of the target variable\n",
    "\n",
    "value_counts = df['No-show'].value_counts()\n",
    "\n",
    "labels = value_counts.index\n",
    "sizes = value_counts.values\n",
    "\n",
    "colors = [green,red]  # Customize colors\n",
    "explode = (0.05, 0)  # Explode the 1st slice\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, explode=explode)\n",
    "\n",
    "plt.title('Distribution of No-Show Variable')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures the pie chart is circular\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 in 5 appointments are missed on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which age group misses more appointments?\n",
    "\n",
    "# Plot histogram with split bars\n",
    "\n",
    "plt.hist([df[df['No-show'] == 'No']['Age'], df[df['No-show'] == 'Yes']['Age']],\n",
    "         bins=10, color=['green', 'red'], alpha=0.7, edgecolor='black', label=['No', 'Yes'], stacked=True)\n",
    "\n",
    "plt.title('Overall Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "# To add % later:\n",
    "\n",
    "# n, bins, _ = plt.hist([df[df['No-show'] == 'No']['Age'], df[df['No-show'] == 'Yes']['Age']],\n",
    "#          bins=10, color=['green', 'red'], alpha=0.7, edgecolor='black', label=['No', 'Yes'], stacked=True)\n",
    "\n",
    "# for i in range(len(bins) - 1):\n",
    "#     total = n[0][i] + n[1][i]\n",
    "#     plt.text((bins[i] + bins[i + 1]) / 2, total, f'{n[0][i] / total:.0%}', ha='center', va='bottom')\n",
    "#     plt.text((bins[i] + bins[i + 1]) / 2, total, f'{n[1][i] / total:.0%}', ha='center', va='top')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an even distribution of the ratio of appointments missed in the various age groups. This tends to change after age 70 where appointments are missed a lot less.\n",
    "\n",
    "This could be explained by the fact that older people cannot afford to miss appointments due to more serious health issues and due to the fact that they might have more time on their hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which gender misses more appointments?\n",
    "\n",
    "# Group by 'gender' and 'no_show' and count occurrences\n",
    "grouped_data = df.groupby(['Sex', 'No-show']).size().unstack()\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = grouped_data.div(grouped_data.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Plotting a grouped bar chart\n",
    "ax = percentages.plot(kind='bar', stacked=True, color=[green, red])\n",
    "\n",
    "# Annotate bars with percentages\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.annotate(f'{height:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.title('Gender-wise No-show Distribution')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('# Appointments')\n",
    "plt.legend(title='No-show', loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be 1 in 5 appointments missed for both genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do patients of a certain community miss their appointments more than others?\n",
    "\n",
    "# Count the total number of appointments per community\n",
    "total_appointments_per_community = df['Community'].value_counts()\n",
    "\n",
    "# Sort the DataFrame based on the total number of appointments\n",
    "sorted_df = df[df['Community'].isin(total_appointments_per_community.index)].copy()\n",
    "sorted_df['Community'] = pd.Categorical(sorted_df['Community'], categories=total_appointments_per_community.index, ordered=True)\n",
    "sorted_df = sorted_df.sort_values(by=['Community'])\n",
    "\n",
    "# Count the number of appointments per community split by show_up status\n",
    "appointments_per_community_show_up = sorted_df.groupby(['Community', 'No-show']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar chart for total appointments per community\n",
    "total_appointments_per_community.loc[sorted_df['Community'].unique()].plot(kind='bar', ax=ax, color='blue', label='Total Appointments')\n",
    "\n",
    "# Bar chart for appointments per community split by show_up status\n",
    "appointments_per_community_show_up.plot(kind='bar', stacked=True, ax=ax, color=['green', 'red'], label=['Show Up', 'No Show Up'])\n",
    "\n",
    "# Adding labels and legend\n",
    "ax.set_title('Appointments per Community')\n",
    "ax.set_xlabel('Community')\n",
    "ax.set_ylabel('Number of Appointments')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Cleaning and Preprocessing (incl. additional EDA)\n",
    "\n",
    "- Dropping erroneous data\n",
    "- Updating Existing Features: Get the columns into the right data types (has some errors but delayed due to non-urgency)\n",
    "- Updating Existing Features: Handling Missing Data: Extrapolation + Imputation (?)\n",
    "- Adding New Features: Time between ScheduledDate and AppointmentDate\n",
    "- Standardization of Continuous variable: yes or no?\n",
    "- OneHotEncoding for Categorical Vairables\n",
    "- Feature Selection based on Correlation Matrix\n",
    "- Feature Selection based on Information Gain\n",
    "- Feature Selection based on Automated Methods i.e. SelectKBest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping original df intact:\n",
    "\n",
    "df_t = df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Type Consistency\n",
    "\n",
    "df_t.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping erroneous data\n",
    "\n",
    "# Dropping inconsistent dates from transformed dataframe\n",
    "\n",
    "df_t = df_t.drop(df[df['ScheduledDate'] > df['AppointmentDate']].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping outliers for Handcap: 2, 3, 4\n",
    "\n",
    "df_t['Handcap'] = df_t['Handcap'][df_t['Handcap'].isin(['yes', 'no'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ = df_t.groupby('Handcap').size().reset_index()\n",
    "print(occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PatientId and Age are to be converted to int from float as IDs must be int/str and ages are usually considered in whole number terms.\n",
    "\n",
    "# Has an error!!!\n",
    "\n",
    "# df_t[\"PatientId\"] = pd.to_numeric(df[\"PatientId\"], errors='coerce').astype(int)\n",
    "# df_t[\"Age\"] = pd.to_numeric(df[\"Age\"], errors='coerce').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrapolating missing data\n",
    "\n",
    "missing_columns = ['Age', 'Community', 'SocialWelfare', 'Hipertension', 'Alcoholism']\n",
    "\n",
    "for column in missing_columns:\n",
    "    df_t[column] = df_t.groupby('PatientId')[column].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df_t.isnull().sum()\n",
    "total_entries = len(df_t)\n",
    "percentage_missing = round((missing_data / total_entries) * 100, 2)\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage Missing': percentage_missing\n",
    "})\n",
    "\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping missing values for time being. In the future we could also use the KNN imputer to fill empty values.\n",
    "\n",
    "df_t.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprx loss of data\n",
    "\n",
    "(1- (df_t.count()/ df.count())) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding New Features: Time between ScheduledDate and AppointmentDate\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "df_t['time_bw_schedule_appointment'] = df_t['AppointmentDate'] - df_t['ScheduledDate']\n",
    "\n",
    "## Convert to float (days)\n",
    "\n",
    "df_t['time_bw_schedule_appointment'] = df_t['time_bw_schedule_appointment'] / pd.Timedelta(days=1)\n",
    "df_t['time_bw_schedule_appointment'] = df_t['time_bw_schedule_appointment'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram with split bars ## EDA and can be removed later.\n",
    "\n",
    "plt.hist([df_t[df_t['No-show'] == 'No']['time_bw_schedule_appointment'], df_t[df_t['No-show'] == 'Yes']['time_bw_schedule_appointment']],\n",
    "         bins=10, color=['green', 'red'], alpha=0.7, edgecolor='black', label=['No', 'Yes'], stacked=True)\n",
    "\n",
    "plt.title('Time Diff Distribution')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take relevant columns for correlation matrix\n",
    "\n",
    "df_sub = df_t[['Diabetes', 'Sex', 'Alcoholism', 'Hipertension', 'SMS_received', 'Handcap', 'time_bw_schedule_appointment', 'No-show']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: Correlation Matrix to understand which features have highest correlation with target variable and less correlation amongst each other.\n",
    "\n",
    "df_t_encoded = pd.get_dummies(df_sub, columns=['Diabetes', 'Sex', 'Alcoholism', 'Hipertension', 'SMS_received', 'Handcap', 'No-show'], drop_first=True).astype(int)\n",
    "correlation_matrix = df_t_encoded.corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection based on Info Gain\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = df_t_encoded.drop(\"No-show_Yes\", axis=1)\n",
    "y = df_t_encoded['No-show_Yes']\n",
    "\n",
    "importances = mutual_info_classif(X, y)\n",
    "feature_importances = pd.Series(importances, df_t_encoded.columns[0:len(df_t_encoded.columns)-1])\n",
    "feature_importances.plot(kind=\"bar\", color=\"teal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_regression, f_classif\n",
    "from numpy import array\n",
    "\n",
    "# Create training set and prediction target\n",
    "X = df_t_encoded.drop(\"No-show_Yes\", axis=1)\n",
    "y = df_t_encoded['No-show_Yes']\n",
    "\n",
    "# Perform feature selection\n",
    "# Set k to the number of features you want to identify\n",
    "select = SelectKBest(score_func=f_classif, k=4)\n",
    "select.fit_transform(X,y)\n",
    "\n",
    "# Print feature names\n",
    "filter = select.get_support() \n",
    "features = array(X.columns)\n",
    " \n",
    "print(\"Selected best:\")\n",
    "print(features[filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_t.applymap(lambda x: x.capitalize() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_t.drop(columns=['No-show', 'PatientId', 'AppointmentID', 'ScheduledDate', 'AppointmentDate', 'Community'])\n",
    "y = df_t['No-show']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding of Categorical Variables\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='if_binary')\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [('OneHotEncoder', ohe, ['SocialWelfare', 'Diabetes', 'Sex', 'Alcoholism', 'Hipertension', 'SMS_received', 'Handcap'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "ct.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ct.fit_transform(X_train)\n",
    "\n",
    "df_X = pd.DataFrame(x)\n",
    "\n",
    "print(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', ct),\n",
    "    ('classifier', clf)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "display_labels=['No-Show', 'Show']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                               display_labels=display_labels)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the processing for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping original df intact:\n",
    "\n",
    "df_test = pd.read_csv('/Users/muhammadraza/Documents/GitHub/BIPM/Data Science/Project/test.csv')\n",
    "\n",
    "df_test_t = df_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Type Consistency\n",
    "\n",
    "df_test_t.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping erroneous data\n",
    "\n",
    "# No need to change dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping outliers for Handcap: 2, 3, 4\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df_test_t['Handcap'] = np.where(df_test_t['Handcap'] != 'yes', 'no', df_test_t['Handcap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrapolating missing data\n",
    "\n",
    "missing_columns = ['Age', 'Community', 'SocialWelfare', 'Hipertension', 'Alcoholism']\n",
    "\n",
    "for column in missing_columns:\n",
    "    df_test_t[column] = df_test_t.groupby('PatientId')[column].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding New Features: Time between ScheduledDate and AppointmentDate\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "df_test_t['AppointmentDate'] = df_test_t['AppointmentDate'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').date())\n",
    "df_test_t['ScheduledDate'] = df_test_t['ScheduledDate'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ').date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test_t['time_bw_schedule_appointment'] = df_test_t['AppointmentDate'] - df_test_t['ScheduledDate']\n",
    "\n",
    "## Convert to float (days)\n",
    "\n",
    "df_test_t['time_bw_schedule_appointment'] = df_test_t['time_bw_schedule_appointment'] / pd.Timedelta(days=1)\n",
    "df_test_t['time_bw_schedule_appointment'] = df_test_t['time_bw_schedule_appointment'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take relevant columns for correlation matrix\n",
    "\n",
    "df_sub_test = df_test_t[['Diabetes', 'Sex', 'Alcoholism', 'Hipertension', 'SMS_received', 'Handcap', 'time_bw_schedule_appointment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_t = df_test_t.applymap(lambda x: x.capitalize() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_test = df_test_t.drop(columns=['PatientId', 'AppointmentID', 'ScheduledDate', 'AppointmentDate', 'Community'])\n",
    "\n",
    "X_df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['impute_age__Age', 'impute_cat__SocialWelfare',\n",
       "       'impute_cat__Diabetes', 'impute_cat__Alcoholism',\n",
       "       'impute_cat__Hipertension', 'OneHotEncoder__SocialWelfare_Yes',\n",
       "       'OneHotEncoder__SocialWelfare_nan', 'OneHotEncoder__Diabetes_Yes',\n",
       "       'OneHotEncoder__Sex_M', 'OneHotEncoder__Alcoholism_Yes',\n",
       "       'OneHotEncoder__Alcoholism_nan', 'OneHotEncoder__Hipertension_Yes',\n",
       "       'OneHotEncoder__Hipertension_nan',\n",
       "       'OneHotEncoder__SMS_received_Yes', 'OneHotEncoder__Handcap_Yes',\n",
       "       'remainder__time_bw_schedule_appointment'], dtype=object)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer_cont = SimpleImputer(strategy=\"median\", add_indicator=False)\n",
    "imputer_cat = SimpleImputer(strategy=\"most_frequent\", add_indicator=False)\n",
    "\n",
    "ct_test = ColumnTransformer(\n",
    "    [('impute_age', imputer_cont, ['Age']),\n",
    "    ('impute_cat', imputer_cat, ['SocialWelfare', 'Diabetes','Alcoholism', 'Hipertension']),\n",
    "    ('OneHotEncoder', ohe, ['SocialWelfare', 'Diabetes', 'Sex', 'Alcoholism', 'Hipertension', 'SMS_received', 'Handcap'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "ct_test.fit_transform(X_df_test)\n",
    "\n",
    "ct_test.get_feature_names_out()\n",
    "\n",
    "## Has 9 columns as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['impute_num__Age', 'impute_cat__SocialWelfare_No',\n",
       "       'impute_cat__SocialWelfare_Yes', 'impute_cat__Diabetes_No',\n",
       "       'impute_cat__Diabetes_Yes', 'impute_cat__Sex_F',\n",
       "       'impute_cat__Sex_M', 'impute_cat__Alcoholism_No',\n",
       "       'impute_cat__Alcoholism_Yes', 'impute_cat__Hipertension_No',\n",
       "       'impute_cat__Hipertension_Yes', 'impute_cat__SMS_received_No',\n",
       "       'impute_cat__SMS_received_Yes', 'impute_cat__Handcap_No',\n",
       "       'impute_cat__Handcap_Yes'], dtype=object)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipelines for numeric and categorical features\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\", add_indicator=False)),\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\", add_indicator=False)),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Combine numeric and categorical transformations in a ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('impute_num', numeric_pipeline, ['Age']),\n",
    "    ('impute_cat', categorical_pipeline, ['SocialWelfare', 'Diabetes', 'Sex', 'Alcoholism', 'Hipertension', 'SMS_received', 'Handcap'])\n",
    "])\n",
    "preprocessor.fit_transform(X_df_test)\n",
    "preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# occ_test = X_df_test.groupby('Sex').size().reset_index()\n",
    "# print(occ_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [('OneHotEncoder', ohe, ['SocialWelfare', 'Diabetes', 'Sex', 'Alcoholism', 'Hipertension', 'SMS_received', 'Handcap'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "ct.fit_transform(X_df_test)\n",
    "\n",
    "ct.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipe.predict(X_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Model Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Fine-Tuning and Optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
